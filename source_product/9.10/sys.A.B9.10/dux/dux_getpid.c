/* $Source: /source/hpux_source/kernel/sys.SWT68K_800/dux/RCS/dux_getpid.c,v $
 * $Revision: 1.5.83.3 $	$Author: root $
 * $State: Exp $   	$Locker:  $
 * $Date: 93/09/17 16:40:53 $
 */

/* 
(c) Copyright 1983, 1984, 1985, 1986, 1987, 1988 Hewlett-Packard Company.
(c) Copyright 1979 The Regents of the University of Colorado, a body corporate 
(c) Copyright 1979, 1980, 1983 The Regents of the University of California
(c) Copyright 1980, 1984, 1986 AT&T Technologies.  All Rights Reserved.
The contents of this software are proprietary and confidential to the Hewlett-
Packard Company, and are limited in distribution to those with a direct need
to know.  Individuals having access to this software are responsible for main-
taining the confidentiality of the content and for keeping the software secure
when not in use.  Transfer to any party is strictly forbidden other than as
expressly permitted in writing by Hewlett-Packard Company.  Unauthorized trans-
fer to or possession by any unauthorized party may be a criminal offense.

                    RESTRICTED RIGHTS LEGEND

          Use,  duplication,  or disclosure by the Government  is
          subject to restrictions as set forth in subdivision (b)
          (3)  (ii)  of the Rights in Technical Data and Computer
          Software clause at 52.227-7013.

                     HEWLETT-PACKARD COMPANY
                        3000 Hanover St.
                      Palo Alto, CA  94304
*/

/*
 *This file contains the code to guarantee that each process in the cluster
 *gets a unique process ID (PID).
 *
 *To get a new process ID call getnewpid().  This will return a unique (within
 *the cluster) process ID.  A few process IDs (for example, for the page
 *demon or for init), are generated by bypassing the call to getnewpid().
 *Such a value is not guaranteed to be unique, even on the site, let alone
 *within the cluster, so it should only be used with care.
 *
 *The algorithm (for normal allocation) is to have the root server allocate
 *chunks to each site as they need them.  Because PIDs eventually recycle,
 *and because a PID in use cannot be reused, it is important to keep track
 *of which chunks are checked out to which site.  If we do indeed recycle,
 *a chunk still in use should be reallocated to the same same site (which
 *can check to see which pids not to use), rather than giving it to some
 *other site.  Once all PIDs in a chunk are free, the chunk should be returned
 *to the server.
 *
 *This code assumes that process group ID's don't have to be unique
 *throughout the cluster. This may have to be reexamined if/when we
 *do global kill or remote devices with remote terminal affiliation.
 */

#include "../h/param.h"
#include "../h/user.h"
#include "../h/proc.h"
#include "../dux/dm.h"
#include "../dux/dmmsgtype.h"
#include "../h/spinlock.h"

extern int dskless_initialized;
extern caddr_t kmem_alloc();

/*The following constants control allocation of process ID chunks.  We may
 *want to put them in conf.c
 */

#define PIDCHUNK 50	/*PIDCHUNK is the number of PIDs allocated at
			 *one time to a given site*/

#define MAX_CHUNKS_TO_RELEASE 14
			/*Chunks of pids are not released in a constant
			 *manner.  It may be possible that at some times
			 *no chunks can be released, and at other times
			 *many can be released.  This is the maximum
			 *number of chunks that can be released in a
			 *single message
			 *
			 *Note that this value is the maximum for the
			 *struct getpidreq to fit in an mbuf. It might be
			 *good to change this value if the size of either
			 *that struct, the struct dux_mbuf, or the struct
			 *dm_header changes.
			 */

#define CHUNK_PREALLOCATE 5
			/*When we have this many (or fewer PIDs available)
			 *send a request to the server for more chunks.  This
			 *avoids having to wait for PIDs when we reach the end
			 *of the chunk.

/*The following macros provide useful functions*/

/*Return the number of chunks in the whole process ID space*/
#define NUMPIDCHUNKS	((MAXPID+(PIDCHUNK-1))/PIDCHUNK)

/*Return the first PID of a given chunk*/
#define CHUNKTOPID(chunk)	((chunk)*PIDCHUNK)

/*Return the size of a given chunk; always PIDCHUNK except for the last
 *chunk which may be smaller
 */
#if MAXPID%PIDCHUNK==0
#define CHUNKTOSIZE(chunk)	PIDCHUNK
#else
#define CHUNKTOSIZE(chunk)	((chunk)<NUMCHUNKS-1?PIDCHUNK:MAXPID%PIDCHUNK)
#endif

/*Return the chunk containing a given PID*/
#define PIDTOCHUNK(pid)	((pid)/PIDCHUNK)

/*Return TRUE if this site is the PID server (currently the same as the
 *root server*/
#define IM_PID_SERVER()		(root_site == my_site)
/*and vice versa*/
#define IM_NOT_PID_SERVER()	(root_site != my_site)

/* Useful variables */

site_t *pidtable=NULL;
				/*This table lists those sites holding each
				 *chunk.  Since the table is comparatively
				 *large, and is only needed at the root
				 *server, we allocate this at initialization 
				 *time in rootinit() by calling
				 *alloc_pidtable() if dskless_initialized 
				 *and !remoteroot.
				 */

site_t *lastpidchunkallocated;
				/*A pointer to the entry of the last chunk
				 *allocated.  This permits us to continue
				 *searching for chunks where we left off
				 *the last time.  lastpidchunkallocated
				 *is initialized to pidtable - 1 in
				 *alloc_pidtable() after pidtable is 
				 *allocated.
				 */

int availpids[PIDCHUNK];	/*A list of PIDs available in the current
				 *chunk.  An entry of 0 means that
				 *the appropriate PID is already in the
				 *proc table (from a previous loop through
				 *the PIDs), and should be skipped.
				 *Note that the compiled in constant PIDCHUNK
				 *requires that the server and the client have
				 *the same view of this constant.
				 */

int *currentavailpid=NULL;
				/*A pointer to the next available PID in the
				 *availpids array
				 */

int *lastavailpid=NULL;		/*A pointer just past the last available PID
				 *in the avalpids array.  When currentavailpid
				 *equals lastavailpid we must refill
				 */

extern struct pidchunk		/*A list of the chunks held by my site*/
{
	int start;		/*The first pid in the chunk*/
	int end;		/*One past the last pid in the chunk*/
} mypidchunks[];		/*The array is actually defined in space.h,
				 *which unfortunately has its own
				 *copy of this structure declaration.
				 *It's size is NPROC, since it is conceivable
				 *that each process can be in a different
				 *chunk.
				 *An empty entry is indicated by end==0.
				 *(It is impossible for a real chunk to
				 *end with zero, although it can start at
				 *zero.  Initially all entries are zero,
				 *so the table is empty.
				 */

int lastnewpid = -1;		/*The first PID of the last chunk allocated
				 *to my site.  We use this so we can
				 *determine where to start the search
				 *for new pids for my site.
				 */

/*The following variables are used at the client site to aid in allocating
 *chunks.  They are used to help with the preallocating and with to avoid
 *having multiple outstanding PID requests.
 */

int pid_alloc_initiated=0;		/*Allocation has been initiated*/
int pid_alloc_complete=0;		/*The allocation request has been
					 *processed*/
int pid_alloc_responsible=0;		/*A process has taken responsibility
					 *for the allocation*/
int pid_alloc_waiting=0;		/*A process is waiting for PIDs*/
int pid_alloc_first;			/*the first preallocated PID*/
int pid_alloc_size;			/*the size of the preallocated PID*/
int pid_alloc_error;			/*error code, if any, from allocation*/

/*Other random constants and variables*/

/*returns from requestpidchunk*/
#define NO_CHUNKS		0	/*no chunks available*/
#define ALREADY_GOT_THEM	1	/*some other process already got
					 *the chunk you asked for
					 */
#define CHUNK_OK		2	/*got a chunk, just like you asked for*/

extern site_t root_site;

/*
 *Return a new PID.  First see if we have an allocated PID.  If so,
 *return it.  If not, allocate some new PIDs and restart.
 *If we cannot get any slots, return -1.  This can only happen if all the
 *chunks are allocated to other sites and my site doesn't have any.  This
 *can only happen when my site joins the cluster
 */
int
dux_getnewpid()
{
#ifdef BSDJOBCTL
	register short phx;
	register int newpid;
#endif BSDJOBCTL

	/*
	 * Sanity check to make sure we have called alloc_pidtable()
	 * to allocate memory for the pidtable.
	 */
	if ((IM_PID_SERVER()) && (pidtable == NULL))
		panic("dux_getnewpid called before pidtable allocated");
#ifdef	MP
	if (IM_PID_SERVER())
		SPINLOCK(sched_lock);
#endif

restart:
	/*skip over any unavailable slots*/
	while (currentavailpid < lastavailpid && *currentavailpid == 0)
		currentavailpid++;
	/*If it is time to preallocate, do so*/
	if (IM_NOT_PID_SERVER() && !pid_alloc_initiated &&
		lastavailpid-currentavailpid < CHUNK_PREALLOCATE)
			preallocate_pid_chunk();
	/*If we have reached the end of the list, refill the slots*/
	if (currentavailpid >= lastavailpid)
	{
		if (neednewchunk())
			goto restart;
		else {
#ifdef	MP
			if (IM_PID_SERVER())
				SPINUNLOCK(sched_lock);
#endif
			return (-1);	/*couldn't get any PIDs*/
		}
	}
#ifdef BSDJOBCTL

	/* Make sure there isn't an existing process group or session */
	/* on this machine with this available pid. If there is then start */
	/* over   */

	/* Since there are more processes than sessions, and the number
	 * of process ID's not in the session chain exceeds the number
	 * of session ID's not in the process chain, searching the process
	 * queues first is slightly faster in those rare cases where a conflict
	 * actually exists. --renglish
	 */

	newpid = *(currentavailpid++);

	phx = pgrphash[PGRPHASH(newpid)];
	while (phx != 0) {
		if (proc[phx].p_pgrp == newpid)
			goto restart;
		phx = proc[phx].p_pgrphx;
	}

	phx = sidhash[SIDHASH(newpid)];
	while (phx != 0) {
		if (proc[phx].p_sid == newpid)
			goto restart;
		phx = proc[phx].p_sidhx;
	}

#ifdef	MP
	if (IM_PID_SERVER())
		SPINUNLOCK(sched_lock);
#endif
	return(newpid);
#else ! BSDJOBCTL
	/* Return the next available PID*/
	return (*(currentavailpid++));
#endif ! BSDJOBCTL
}

/*
 *We need a new chunk of PIDs.  If I am the server, I can get them locally.
 *If not, get them from the server.  As part of getting new chunks, release
 *any old unused chunks I may be holding.
 *
 *Return 0 if we couldn't get a chunk, 1 otherwise.
 */
int
neednewchunk()
{
	int firstpid;	/*the first PID in the chunk */
	int size;	/*the number of PIDs in the chunk */
	register struct pidchunk *p;
	register struct pidchunk *avail;
	struct pidchunk *found;
	register i, register_tmp;
	register struct proc *rpp;
	int endchain;

	extern returnpidchunk();	/*forward*/

	if (IM_PID_SERVER())
	{
		/*release current chunks*/
		releasefreepidchunks(returnpidchunk,0);
		/* get the chunk */
		if (getpidchunk(lastnewpid,&firstpid,&size))
			return(0);
	}
	else
	{
		/*
		 *get the preallocated chunks
		 */
		switch (getpreallocatedpidchunk(&firstpid,&size))
		{
			case NO_CHUNKS:	/*there were no chunks*/
				return(0);
			case ALREADY_GOT_THEM:	/*some other process already
						 *got the chunks*/
				return(1);

			/* fall though in default case - CHUNK_OK */
		}
	}
	/* At this point we have a chunk.  Firstpid is the first PID, and
	 * size is the number of PIDs
	 */

	/* Remember the PID we were just given */
	lastnewpid = firstpid;

	/* Traverse the table of chunks held by me to see if we are already
	 * in it.  While we are at it, find an entry in the table to put
	 * the new chunk.
	 * Note that the loop counds down instead of up for a slight
	 * improvement in efficiency; the termination test is cheaper.
	 * Note that it is not worth trying to optimize to find a chunk
	 * that is already present quickly, since most of the time the
	 * chunk won't be present at all; it will only be present if we
	 * are recycling.
	 */
	found = avail = NULL;
	for (p=mypidchunks+(nproc-1); p>=mypidchunks; p--)
	{
		if (p->end == 0)	/*a free slot*/
			avail = p;	/*remember it*/
		else if (p->start == firstpid)	/*found it*/
		{
			found = p;
			break;
		}
	}
	/*At this point there are three possibilities.  We may have found it,
	 *in which case found is set...
	 */
	if (found)
		p = found;
	/*Or we may not have found it, but found an available slot...*/
	else if (avail)
	{
		p = avail;
		/*fill in the entry.  We didn't need to do this for found,
		 *because the entry was already filled in.
		 */
		p->start = firstpid;
		p->end = firstpid+size;
	}
	/*Or, there wasn't even an available slot.  This cannot happen,
	 *becuse there is one slot for each possible process, but just
	 *in case...
	 */
	else
		panic ("no pid chunk table entries");
	/*Fill the PIDs into the available PID table*/
	for (i=0, register_tmp=firstpid; i<size; i++, register_tmp++)
	{
		/* 
		 * availpids[i] = firstpid + i;
		 * can't make firstpid a register variable, so
		 * use register_tmp instead.
		 */
		availpids[i] = register_tmp;
	}
	/* If we found the chunk in the PID table, we probably have an
	 * entry in the proc table using the PID.  So traverse the proc
	 * table and find all the PIDs in use and invalidate the entries
	 * in the available PID table.
	 */
	if (found) {
		endchain = 0;
		register_tmp = firstpid + size; /* to avoid calculating
						 * firstpid + size inside
						 * the loop.
						 */
		for (rpp = proc; endchain == 0 ; rpp = &proc[rpp->p_fandx]) {

			if (rpp->p_fandx == 0)
				endchain = 1;

			if (rpp->p_pid>=firstpid &&
				/* rpp->p_pid<firstpid+size */
				rpp->p_pid<register_tmp)
					availpids[rpp->p_pid-firstpid]
						= 0;
		}
	}

	/*Set the next available PID to point to the start of the table.
	 *However, there is a special case of chunk 0, for which PIDs
	 *0 - PID_MAXSYS are reserved, so set the pointer to the
	 * PID_MAXSYS + 1 entry.
	 */
	currentavailpid = firstpid==0?availpids+PID_MAXSYS+1:availpids;
	/*set the pointer to the last entry*/
	lastavailpid = availpids+size;
	return (1);
}

/*
 *Getpidchunk is executed on the server.  It returns a new chunk, setting
 *pidp and sizep to point to the first PID of the chunk and the size of the
 *chunk respectively.  Lastnewpid is a parameter specifying the first PID
 *of the last new chunk allocated by the server.  The algorithm has two
 *steps:
 *
 *1)  Determine if there are any chunks between the last chunk allocated
 *to the requesting site and the last chunk allocated to any site that
 *are already allocated to the requesting site.  If so, give the first
 *such chunk found to the requesting site.  The reason for this step is
 *because of recycling.  When previous sites requested chunks we may
 *have had to skip over this chunk, because the requesting site was
 *holding it.  now, we should let this requesting site get the chunk
 *rather than completely ignoring it.
 *
 *2)  If a chunk wasn't found, search from where we allocated the last chunk to
 *find either a free chunk or a chunk already belonging to the site.  Return
 *that.  If we couldn't find any chunks, return -1.
 *
 */
int
getpidchunk(lastnewpid,pidp,sizep)
int lastnewpid;
int *pidp;
int *sizep;
{
	register site_t *chunkp;

	/*Start after the last chunk allocated to the requesting site, and
	 *continue until the location we are currently allocating from.
	 *See if there is a chunk that belongs to that site but has not
	 *yet been returned.
	 *
	 *Note that this code assumes that u.u_site can never be zero.
	 *If that assumption breaks, u_site == 0 must be special cased.
	 */
	if (lastnewpid >= 0)
	{
		chunkp=pidtable+PIDTOCHUNK(lastnewpid);
		while (chunkp++ != lastpidchunkallocated)
		{
			if (chunkp >= pidtable+NUMPIDCHUNKS)
			{
				chunkp = pidtable-1;
				continue;
			}
			if (*chunkp == u.u_site)	/*found one*/
			{
				*pidp=CHUNKTOPID(chunkp-pidtable);
				*sizep=CHUNKTOSIZE(chunkp-pidtable);
				return (0);
			}
		}
	}
	/*Didn't find one already belonging to the site, give it a new chunk*/
	for (chunkp=lastpidchunkallocated+1;
		chunkp != lastpidchunkallocated; chunkp++)
	{
		if (chunkp >= pidtable+NUMPIDCHUNKS)
		{
			chunkp = pidtable-1;
			continue;
		}
		if (*chunkp == 0 ||
			*chunkp == u.u_site)	/*found one*/
		{
			*pidp=CHUNKTOPID(chunkp-pidtable);
			*sizep=CHUNKTOSIZE(chunkp-pidtable);
			lastpidchunkallocated=chunkp;
			*chunkp=u.u_site;
			return (0);
		}
	}
	/*couldn't find one*/
	return (1);
}

/*
 *Return a pid to the table.  The algorithm is so simple, it needs no
 *explanation.  In fact, this comment is already bigger than the function
 *so don't bother reading it because it contains no useful information.
 *Why are you still reading this?
 */
returnpidchunk(pid)
int pid;
{
	*(pidtable + PIDTOCHUNK(pid)) = 0;
}

/*
 *Search the tables to find any chunks that can be returned.  Unfortunately,
 *this involves searching the complete proc table for each chunk we are
 *holding.  Hopefully, we won't be holding too many chunks most of the time,
 *and we won't call this function that frequently.  (It is currently set up
 *to be called whenever we need a new chunk.
 *
 *This function is passed two parameters, a function and a parameter.  The
 *function should be called for each chunk that needs to be released, and
 *should be passed the first PID of the chunk and the specified parameter.
 *At the server, the function is simply returnpidchunk which returns the
 *chunk directly.  At a non server, the function is fillreleasepidchunk, which
 *adds the new chunk to the list of chunks being released in the message which
 *is passed as the second parameter.
 */
releasefreepidchunks(func,parm)
int (*func)();
caddr_t parm;
{
	register struct pidchunk *p;
	register found;
	register struct proc *rpp;
	register int endchain;

	/* Traverse the chunk table backwards for efficiency */
	for (p = mypidchunks+nproc-1; p >= mypidchunks ; p--)
	{
		if (p->end == 0)	/*If this chunk is free...*/
			continue;	/*ignore it*/
		/*Because of preallocation, it is possible that there are
		 *no entries in the proc table, but that we still have a
		 *few entries to go from the lastchunk.  So, if this
		 *is that last chunk, don't release it
		 */
		if (lastnewpid == p->start)
			continue;
		found=0;

		/*look for it in the proc table*/

		endchain = 0;
		for (rpp = proc; endchain == 0 ; rpp = &proc[rpp->p_fandx]) {

			if (rpp->p_fandx == 0)
				endchain = 1;

			if (rpp->p_pid >= p->start && rpp->p_pid < p->end) {

					/*found it...can't release the chunk*/

					found=1;
					break;
			}
		}

		/*If we didn't find any references to the chunk, we can
		 *release it by calling the appropriate function
		 */

		if (!found)
		{
			(*func)(p->start,parm);
			p->end=0;
		}
	}
}

/*
 *The following functions are used for requesting new chunks from the
 *server.  They include both functions used on the requestnig site and functions
 *used on the serving site.
 *
 *Note that we include any chunks to be released along with requests for a
 *new chunk.  (Although if there are more than MAX_CHUNKS_TO_RELEASE
 *we need to send additional messages; this is unlikely.)
 *
 *First, the data structures used for the messages:
 */

/*The request:*/
struct getpidreq		/*DUX MESSAGE STRUCTURE*/
{
	short lastnewpid;	/*the last PID allocated to me*/
	short number_to_release;/*Number of chunks released with this message*/
	short chunks_to_release[MAX_CHUNKS_TO_RELEASE];	/*chunks being
				 *released with this message*/
};

/*The response:*/
struct getpidresp		/*DUX MESSAGE STRUCTURE*/
{
	short firstpid;		/*the first PID in the chunk*/
	short size;		/*the number of PIDs in the chunk*/
};

/*
 *The following function is called to fill in an entry into the message
 *for a chunk that is being released.  If the message already has the maximum
 *number of chunks being release, we need to send over a special message,
 *just releasing the chunks.
 */

fillreleasepidchunk(pid,message)
int pid;
dm_message message;
{
	register struct getpidreq *reqp = DM_CONVERT(message, struct getpidreq);

	/*is the message already filled to the max?*/

	if (reqp->number_to_release >= MAX_CHUNKS_TO_RELEASE)
	{
		/*send the special message.  Note that we use the
		 *DM_RELEASEPIDS opcode instead of the DM_GETPIDS
		 *opcode to indicate that we are only releasing,
		 *not also getting (both opcodes invoke the same function).
		 */
		dm_send(message, DM_RELEASE_REPLY|DM_SLEEP, DM_RELEASEPIDS,
			root_site, DM_EMPTY, NULL, NULL, NULL, NULL,
			NULL, NULL, NULL);
		/*reset the count so we can begin refilling*/
		reqp->number_to_release = 0;
	}

	/*fill in the entry*/

	reqp->chunks_to_release[reqp->number_to_release++] = pid;
}

/*
 *Send a request to preallocate a chunk.
 *This routine should only be called if:
 *	1) We are not the PID server and,
 *	2) We are not already preallocating chunks (pid_alloc_initiated
 *		is not set.
 *The routine does not check for these conditions.
 */
preallocate_pid_chunk()
{
	dm_message message;
	struct getpidreq *reqp;
	extern recv_pid_reply();	/*forward*/

	/*First set the initiated flag to prevent other processes from
	 *preallocating pids*/

	pid_alloc_initiated++;

	/*allocate a message*/

	message = dm_alloc(sizeof (struct getpidreq), WAIT);
	reqp = DM_CONVERT (message, struct getpidreq);

	/*At this time, release any chunks that can be released*/

	reqp->number_to_release = 0;
	releasefreepidchunks(fillreleasepidchunk, message);

	/*Now, send the request*/

	reqp->lastnewpid = lastnewpid;
	message = dm_send(message, DM_FUNC|DM_RELEASE_REQUEST, DM_GETPIDS,
		root_site, sizeof (struct getpidresp),recv_pid_reply,
		NULL, NULL, NULL, NULL, NULL, NULL);
}

/*
 *Receive the reply to a chunk preallocation.
 *Note that the first parameter is called 'null' to indicate that the
 *request has actually been released by dm_recv_reply
 */
/*ARGSUSED*/
recv_pid_reply(null,reply)
dm_message null,reply;
{
	register struct getpidresp *resp;

	/*set the flag indicating that the preallocation is complete*/

	pid_alloc_complete++;

	/*Interpret the response*/

	resp = DM_CONVERT(reply, struct getpidresp);
	pid_alloc_error = DM_RETURN_CODE(reply);
	pid_alloc_first = resp->firstpid;
	pid_alloc_size = resp->size;
	dm_release(reply, 0);

	/*if a process is waiting for the PIDs, wake it up.  Note that we
	 *check the responsible flag, not the waiting flag.  That is because
	 *the first process to pick up the request will set the responsible
	 *flag, and subsequent processes will set the waiting flag.  The
	 *first one is the one who will fill in all the tables
	 */
	if (pid_alloc_responsible)
		wakeup (&pid_alloc_responsible);
}

/*
 *Get the preallocated chunk.
 *We need to watch out for a race condition which can occur if an additional
 *process is created while we are waiting for new PIDs.  It will also call this
 *function to get new PIDs.  Since we only preallocated one chunk, we need
 *to put the process to sleep and just let it wait for the first process to
 *complete.
 *Return the following values:
 *	NO_CHUNKS		The server couldn't provide any chunks
 *	ALREADY_GOT_THEM	Someone else allocated the chunk
 *	CHUNK_OK		I allocated the chunk
 *In the last case, fill in the values pointed at by pidp and sizep.
 */
getpreallocatedpidchunk(pidp,sizep)
int *pidp;
int *sizep;
{
	int s;

	/*If someone else has already taken responsiblity for this, just wait
	 *for them
	 */
	if (pid_alloc_responsible)
	{
		pid_alloc_waiting++;
		do
			sleep (&pid_alloc_waiting,PZERO-1);
		while (pid_alloc_responsible);
		return (ALREADY_GOT_THEM);
	}
	/*OK, them, I'm responsible*/
	pid_alloc_responsible++;
	/*If the preallocation isn't complete, wait for it*/
	if (!pid_alloc_complete)
	{
		s = splimp();
		while (!pid_alloc_complete)
			sleep (&pid_alloc_responsible,PZERO-1);
		splx(s);
	}
	/*set up the apropriate values based on the request*/
	u.u_error = pid_alloc_error;
	*pidp = pid_alloc_first;
	*sizep = pid_alloc_size;
	/*If anyone is waiting for me, wake them up*/
	if (pid_alloc_waiting)
	{
		wakeup (&pid_alloc_waiting);
	}
	/*clear all the flags.  Note that an assumption is made in clearing
	 *the flags here.  The process that is responsible should immediately
	 *set up the allocated table before any other process is given a
	 *chance to run (or at least fork).  Otherwise, the other process
	 *will think we need new PIDs and will preallocate them
	 */
	pid_alloc_initiated = 0;
	pid_alloc_complete = 0;
	pid_alloc_responsible = 0;
	pid_alloc_waiting = 0;
	return (u.u_error?NO_CHUNKS:CHUNK_OK);
}

/*
 *Service the request for new PIDs.  First release the returned chunks, if any.
 *This routine serves both the DM_GETPIDS and DM_RELEASEPIDS requests.
 *If this request wasn't a release only request, get a new chunk.
 */
serve_getpids(message)
register dm_message message;
{
	register i;
	int firstpid, size;
	register struct getpidreq *reqp = DM_CONVERT(message, struct getpidreq);
	register struct getpidresp *resp;

#ifdef	MP
	if (IM_PID_SERVER())
		SPINLOCK(sched_lock);
#endif
	/* First release any returned chunks */
	for (i = 0; i < reqp->number_to_release; i++)
		returnpidchunk(reqp->chunks_to_release[i]);
	if (DM_OP_CODE(message) == DM_RELEASEPIDS) {	/*release only, no get*/
#ifdef	MP
		if (IM_PID_SERVER())
			SPINUNLOCK(sched_lock);
#endif
		dm_quick_reply(0);
		return;
	}
	/* getting a new chunk (in addition to any releases) */
	if (getpidchunk(reqp->lastnewpid, &firstpid,&size)) {
#ifdef	MP
		if (IM_PID_SERVER())
			SPINUNLOCK(sched_lock);
#endif
		dm_quick_reply(EAGAIN);
		return;
	}
#ifdef	MP
	if (IM_PID_SERVER())
		SPINUNLOCK(sched_lock);
#endif
	DM_SHRINK(message, sizeof (struct getpidresp));
	resp = DM_CONVERT(message, struct getpidresp);
	resp->firstpid = firstpid;
	resp->size = size;
	dm_reply (message, 0, 0, NULL, NULL, NULL);
}

/*cleanup PIDs when a site fails.  Just return all PIDs owned by that site
 *to the pool
 */
pid_cleanup(site)
register site_t site;
{
	register site_t *p;
	if (IM_PID_SERVER())
	{
		for (p=pidtable; p<pidtable+NUMPIDCHUNKS; p++)
			if (*p == site)
				*p = 0;
	}
	/* return 0, so recovery code knows we we're successful */
	return(0);
}

/*
 * Allocate memory for the pidtable.  Called from rootinit() if we are
 * a root server or standalone system with dskless configured.
 */
int
alloc_pidtable()
{
	pidtable = (site_t *) kmem_alloc((sizeof(site_t)*NUMPIDCHUNKS));
	if (pidtable == NULL)
		panic("alloc_pidtable: Can't allocate memory for pidtable");
	bzero((caddr_t)pidtable, (sizeof(site_t)*NUMPIDCHUNKS));
	/*
	 * initialize lastpidchunkallocated now that we have a value
	 * pidtable.
	 */
	lastpidchunkallocated = pidtable - 1;
}
